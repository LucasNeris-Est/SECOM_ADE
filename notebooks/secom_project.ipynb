{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final - Aprendizado de Máquina\n",
    "## Análise do Dataset SECOM\n",
    "\n",
    "Este notebook implementa o pipeline solicitado no trabalho final da disciplina.\n",
    "\n",
    "### Estrutura:\n",
    "1. Carregamento e exploração dos dados (EDA)\n",
    "2. Pré-processamento (imputação, escalonamento, remoção de colunas constantes)\n",
    "3. Redução de dimensionalidade (PCA/LDA)\n",
    "4. Modelagem\n",
    "5. Resultados e Comparação\n",
    "6. Resultados e Comparação\n",
    "7. Ajustando limiar de decisão do melhor modelo\n",
    "7. Conclusões\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas principais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline # Pipeline especial para SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import average_precision_score,precision_recall_curve\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Exploração dos Dados (EDA)\n",
    "Carregaremos o dataset SECOM.\n",
    "- Arquivo `secom.data` contém as features\n",
    "- Arquivo `secom_labels.data` contém as labels (-1 = Pass, 1 = Fail)\n",
    "\n",
    "Além disso, já e feito a divisão entre treino e teste para evitar data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste os caminhos para os arquivos antes de executar\n",
    "X = pd.read_csv('../data/raw/secom.data', sep=' ', header=None, na_values='NaN')\n",
    "# Converta os nomes para string para evitar ambiguidades\n",
    "X.columns = X.columns.astype(str)\n",
    "y = pd.read_csv('../data/raw/secom_labels.data', sep=' ', header=None, usecols=[0])\n",
    "y = y[0]\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Shape y:\", y.shape)\n",
    "print(\"Classes:\", y.value_counts())\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorando quantidade de NA's em cada coluna\n",
    "X.isna().mean().sort_values(ascending=False).head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97493408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae3cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O split é feito ANTES de qualquer processamento para simular dados \"novos\" no teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento\n",
    "- Removendo variáveis com mais de 40% de valores faltantes\n",
    "- Imputação de valores faltantes (média)\n",
    "- Remoção de colunas constantes\n",
    "- Padronização (z-score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207fcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para remoção de colunas com 40 de NA\n",
    "\n",
    "class ColumnDropperByNa(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.4):\n",
    "        self.threshold = threshold\n",
    "        self.columns_to_keep_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Aprende quais colunas manter APENAS dos dados de treino (X)\n",
    "        nan_frac = X.isna().mean()\n",
    "        self.columns_to_keep_ = X.columns[nan_frac < self.threshold].tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Aplica a transformação, mantendo apenas as colunas aprendidas\n",
    "        return X[self.columns_to_keep_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Criar pipeline de pré processamento inical\n",
    "# -----------------------\n",
    "\n",
    "preprocessor_pipeline = Pipeline(steps=[\n",
    "    ('remover_por_na', ColumnDropperByNa(threshold=0.4)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('remover_constantes', VarianceThreshold()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# -----------------------\n",
    "# Aplicar transformação aos dados\n",
    "# -----------------------\n",
    "X_train_transformed = preprocessor_pipeline.fit_transform(X_train)\n",
    "\n",
    "# Voltar para DataFrame\n",
    "X_train_prepared = pd.DataFrame(X_train_transformed)\n",
    "\n",
    "print(\"Shape antes:\", X_train.shape)\n",
    "print(\"Shape depois:\", X_train_prepared.shape)\n",
    "print(X_train_prepared.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Redução de Dimensionalidade (PCA/LDA)\n",
    "Aplicaremos PCA para reduzir a dimensionalidade e visualizar os dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train_prepared)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=y_train, palette='coolwarm', alpha=0.7)\n",
    "plt.title('Projeção PCA (2 componentes)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50020e8c",
   "metadata": {},
   "source": [
    "A análise via PCA demonstrou que as direções de maior variância nos dados não são as mesmas que separam eficientemente as classes de operação normal das falhas, resultando em uma sobreposição visual significativa. Isso ocorre porque o PCA é uma técnica não supervisionada, que ignora os rótulos ao projetar os dados. Diante disso, a utilização da Análise de Discriminante Linear (LDA) é a próxima etapa lógica. Diferentemente do PCA, o LDA é um método supervisionado cujo objetivo é encontrar a projeção dos dados que maximiza a separação entre as classes. Portanto, ao invés de buscar a variância, o LDA buscará o eixo que melhor distingue os grupos, o que pode revelar uma estrutura de separação que não era visível com o PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0e6feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como há 2 classes, usamos n_components=1\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_lda = lda.fit_transform(X_train_prepared, y_train) # Note que 'y' é passado aqui!\n",
    "\n",
    "# Para visualizar, podemos plotar a densidade de cada classe\n",
    "df_lda = pd.DataFrame({'LD1': X_lda.flatten(), 'label': y_train})\n",
    "sns.displot(df_lda, x='LD1', hue='label', kind='kde', fill=True)\n",
    "plt.title('Separação das Classes usando LDA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4739f1",
   "metadata": {},
   "source": [
    "A análise com LDA (Análise de Discriminante Linear) foi bem-sucedida, demonstrando, ao contrário do PCA, que o problema é amplamente separável. A técnica projetou os dados de alta dimensão em um único eixo (LD1) no qual as duas classes apresentam distribuições claramente distintas: a classe normal (-1) forma um grupo denso e consistente, enquanto a classe de falha (1) se concentra em uma região separada, embora com maior variabilidade. Este resultado é extremamente promissor, pois confirma que um modelo de classificação pode aprender uma fronteira linear para distinguir os casos com alta eficácia, transformando um problema complexo em um que é visivelmente mais simples de resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelagem\n",
    "Usaremos Logistic Regression, Random Forest e SVM.\n",
    "- Cada um com pelo menos 2 variações de hiperparâmetros via GridSearch.\n",
    "- Validação com Stratified 10-Fold Cross Validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a19dc",
   "metadata": {},
   "source": [
    "### Modelagem sem LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. DEFINIÇÃO DOS CENÁRIOS DE PRÉ-PROCESSAMENTO\n",
    "# ==============================================================================\n",
    "\n",
    "# Definimos os dois pré-processadores base\n",
    "preprocessor_base = Pipeline(steps=[\n",
    "    ('remover_por_na', ColumnDropperByNa(threshold=0.4)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('remover_constantes', VarianceThreshold()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor_lda = Pipeline(steps=[\n",
    "    ('remover_por_na', ColumnDropperByNa(threshold=0.4)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('remover_constantes', VarianceThreshold()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lda', LinearDiscriminantAnalysis(n_components=1))\n",
    "])\n",
    "\n",
    "# Agora criamos uma lista de configurações para cada cenário que queremos testar\n",
    "scenarios = [\n",
    "    {'name': 'Sem LDA, Sem SMOTE', 'preprocessor': preprocessor_base, 'use_smote': False},\n",
    "    {'name': 'Com LDA, Sem SMOTE', 'preprocessor': preprocessor_lda, 'use_smote': False},\n",
    "    {'name': 'Sem LDA, Com SMOTE', 'preprocessor': preprocessor_base, 'use_smote': True},\n",
    "    {'name': 'Com LDA, Com SMOTE', 'preprocessor': preprocessor_lda, 'use_smote': True},\n",
    "]\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DEFINIÇÃO ÚNICA DOS MODELOS E PARÂMETROS\n",
    "# ==============================================================================\n",
    "# (Mesma definição de antes)\n",
    "models_and_params = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced'),\n",
    "        'params': { 'model__C': [0.01, 0.1, 1, 10], 'model__penalty': ['l2'] }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        'params': { 'model__n_estimators': [100, 200], 'model__max_depth': [10, 20], 'model__min_samples_leaf': [1, 5] }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(probability=True, random_state=42, class_weight='balanced'),\n",
    "        'params': { 'model__C': [0.1, 1, 10], 'model__kernel': ['linear', 'rbf'], 'model__gamma': ['scale', 'auto'] }\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'model': LGBMClassifier(random_state=42),\n",
    "        'params': { 'model__n_estimators': [100, 200], 'model__learning_rate': [0.05, 0.1], 'model__scale_pos_weight': [10, 20, 30] }\n",
    "    }\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. LOOP ÚNICO DE TREINAMENTO E AVALIAÇÃO\n",
    "# ==============================================================================\n",
    "all_results = []\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. LOOP ÚNICO DE TREINAMENTO E AVALIAÇÃO (CORRIGIDO)\n",
    "# ==============================================================================\n",
    "all_results = []\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    scenario_name = scenario['name']\n",
    "    preprocessor = scenario['preprocessor']\n",
    "    use_smote = scenario['use_smote']\n",
    "    \n",
    "    print(f\"--- EXECUTANDO CENÁRIO: {scenario_name} ---\")\n",
    "    \n",
    "    for model_name, config in models_and_params.items():\n",
    "        print(f\"\\nTreinando {model_name}...\")\n",
    "        \n",
    "        # --- INÍCIO DA CORREÇÃO ---\n",
    "        # Em vez de começar com o pipeline, começamos com a lista de passos DENTRO dele\n",
    "        pipeline_steps = preprocessor.steps.copy() \n",
    "        # --- FIM DA CORREÇÃO ---\n",
    "        \n",
    "        model = config['model']\n",
    "        params = config['params'].copy()\n",
    "        \n",
    "        if use_smote:\n",
    "            pipeline_steps.append(('smote', SMOTE(random_state=42)))\n",
    "            if 'class_weight' in model.get_params():\n",
    "                model.set_params(class_weight=None)\n",
    "            if 'model__scale_pos_weight' in params:\n",
    "                del params['model__scale_pos_weight']\n",
    "        \n",
    "        pipeline_steps.append(('model', model))\n",
    "        \n",
    "        if use_smote:\n",
    "            full_pipeline = ImbPipeline(steps=pipeline_steps)\n",
    "        else:\n",
    "            full_pipeline = Pipeline(steps=pipeline_steps)\n",
    "            \n",
    "        grid = GridSearchCV(full_pipeline, params, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=0)\n",
    "        grid.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        all_results.append({\n",
    "            'scenario': scenario_name,\n",
    "            'model': model_name,\n",
    "            'roc_auc_test': roc_auc_score(y_test, y_prob),\n",
    "            'auprc_test': average_precision_score(y_test, y_prob), \n",
    "            'balanced_accuracy_test': balanced_accuracy_score(y_test, y_pred),\n",
    "            'f1_test': f1_score(y_test, y_pred, pos_label=1),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
    "            'best_params': grid.best_params_\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Resultados e Comparação\n",
    "Aqui apresentamos os resultados de cada classificador no conjunto de teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a lista de resultados em um DataFrame do Pandas\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# 1. Tabela Comparativa usando AUPRC (ou Balanced Accuracy)\n",
    "print(\"\\n## Tabela Comparativa (AUPRC no Teste) ##\")\n",
    "comparison_table = results_df.pivot_table(\n",
    "    index='model', \n",
    "    columns='scenario', \n",
    "    values='auprc_test' # <-- MUDANÇA PRINCIPAL AQUI\n",
    ")\n",
    "\n",
    "# Reordena as colunas para uma melhor visualização lógica\n",
    "comparison_table = comparison_table[['Sem LDA, Sem SMOTE', 'Sem LDA, Com SMOTE', 'Com LDA, Sem SMOTE', 'Com LDA, Com SMOTE']]\n",
    "print(comparison_table.round(4))\n",
    "\n",
    "# 2. Detalhes e Matriz de Confusão para cada experimento\n",
    "for result in all_results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"## Modelo: {result['model']} | Cenário: {result['scenario']} ##\")\n",
    "    print(f\"ROC AUC (Teste): {result['roc_auc_test']:.4f}\")\n",
    "    print(f\"Melhores Hiperparâmetros: {result['best_params']}\")\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(result['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Matriz de Confusão - {result['model']} ({result['scenario']})\")\n",
    "    plt.ylabel('Label Verdadeiro')\n",
    "    plt.xlabel('Label Previsto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ajustando limiar de decisão do melhor modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 1: SELECIONAR E RETREINAR O MODELO CAMPEÃO \n",
    "# (Esta parte já funcionou para você, mantida para contexto)\n",
    "# ==============================================================================\n",
    "print(\"--- Iniciando o ajuste do limiar para o melhor modelo ---\")\n",
    "\n",
    "CENARIO_VENCEDOR = 'Sem LDA, Sem SMOTE'\n",
    "MODELO_VENCEDOR = 'RandomForest'\n",
    "\n",
    "try:\n",
    "    best_model_config = next(item for item in all_results if item[\"model\"] == MODELO_VENCEDOR and item[\"scenario\"] == CENARIO_VENCEDOR)\n",
    "except (NameError, StopIteration):\n",
    "    print(\"ERRO: A variável 'all_results' não foi encontrada ou o modelo/cenário vencedor não está nela.\")\n",
    "    exit()\n",
    "\n",
    "best_params = best_model_config['best_params']\n",
    "model_params = {key.replace('model__', ''): value for key, value in best_params.items()}\n",
    "\n",
    "best_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', RandomForestClassifier(random_state=42, class_weight='balanced', **model_params))\n",
    "])\n",
    "\n",
    "print(\"Retreinando o modelo campeão com os melhores parâmetros...\")\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2, 3: OBTER PROBABILIDADES E PADRONIZAR RÓTULOS\n",
    "# (Mantidos como antes)\n",
    "# ==============================================================================\n",
    "y_probs_train = best_pipeline.predict_proba(X_train)[:, 1]\n",
    "y_probs_test = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "y_train_mapped = y_train.replace({-1: 0})\n",
    "y_test_mapped = y_test.replace({-1: 0})\n",
    "print(\"Probabilidades previstas e rótulos mapeados.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: ENCONTRAR O LIMIAR ÓTIMO (Lógica Levemente Ajustada)\n",
    "# ==============================================================================\n",
    "precision, recall, thresholds = precision_recall_curve(y_train_mapped, y_probs_train)\n",
    "\n",
    "# Calcula o F1-score para cada limiar\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "f1_scores = np.nan_to_num(f1_scores)\n",
    "\n",
    "# Encontra o melhor limiar (considerando apenas os N primeiros scores)\n",
    "best_f1_idx = np.argmax(f1_scores[:-1])\n",
    "best_threshold = thresholds[best_f1_idx]\n",
    "\n",
    "print(f\"\\nMelhor F1-Score (no treino): {f1_scores[best_f1_idx]:.4f}\")\n",
    "print(f\"Limiar ótimo encontrado: {best_threshold:.4f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 5: VISUALIZAR O TRADE-OFF (CORRIGIDO)\n",
    "# ==============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Usamos thresholds como eixo X e fatiamos os outros arrays para terem o mesmo tamanho\n",
    "plt.plot(thresholds, precision[:-1], label='Precision', color='blue')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall', color='green')\n",
    "plt.plot(thresholds, f1_scores[:-1], label='F1-Score', color='red', linestyle='--') # <-- CORREÇÃO APLICADA\n",
    "plt.axvline(x=best_threshold, color='black', linestyle=':', label=f'Limiar Ótimo ({best_threshold:.2f})')\n",
    "plt.title('Precision, Recall e F1-Score vs. Limiar de Decisão (Dados de Treino)')\n",
    "plt.xlabel('Limiar de Probabilidade')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 6: AVALIAR O DESEMPENHO FINAL NO CONJUNTO DE TESTE\n",
    "# (Mantido como antes)\n",
    "# ==============================================================================\n",
    "y_pred_test_optimized = (y_probs_test >= best_threshold).astype(int)\n",
    "\n",
    "cm_optimized = confusion_matrix(y_test_mapped, y_pred_test_optimized)\n",
    "new_f1_score = f1_score(y_test_mapped, y_pred_test_optimized)\n",
    "new_ba_score = balanced_accuracy_score(y_test_mapped, y_pred_test_optimized)\n",
    "\n",
    "print(\"\\n--- RESULTADOS FINAIS NO CONJUNTO DE TESTE (COM LIMIAR OTIMIZADO) ---\")\n",
    "print(f\"F1-Score: {new_f1_score:.4f}\")\n",
    "print(f\"Balanced Accuracy: {new_ba_score:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_optimized, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=['Previsto Normal (0)', 'Previsto Falha (1)'],\n",
    "            yticklabels=['Real Normal (0)', 'Real Falha (1)'])\n",
    "plt.title(f'Matriz de Confusão Final (Limiar = {best_threshold:.2f})')\n",
    "plt.ylabel('Label Verdadeiro')\n",
    "plt.xlabel('Label Previsto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d98c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use apenas o pipeline do RandomForest Sem LDA, Sem SMOTE\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('model', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Nova grade de parâmetros focada em regularização\n",
    "params_rf_regularized = {\n",
    "    'model__n_estimators': [100, 200],\n",
    "    'model__max_depth': [3, 5, 7, 10], # Teste árvores BEM mais simples\n",
    "    'model__min_samples_leaf': [10, 20, 50], # Force as folhas a serem maiores\n",
    "    'model__max_features': ['sqrt', 0.3, 0.5] # Limite as features por árvore\n",
    "}\n",
    "\n",
    "print(\"\\n--- INICIANDO NOVO TREINO DO RANDOMFOREST COM REGULARIZAÇÃO FORTE ---\")\n",
    "grid_rf_reg = GridSearchCV(rf_pipeline, params_rf_regularized, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Após o treino, você deve repetir o processo de ajuste de limiar com este novo `grid_rf_reg.best_estimator_`\n",
    "# e avaliar os resultados no teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb826708",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Iniciando o ajuste do limiar para o NOVO modelo regularizado ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 1: OBTER O MELHOR ESTIMADOR DO NOVO GRIDSEARCH\n",
    "# ==============================================================================\n",
    "# Pegamos o melhor pipeline encontrado pelo novo GridSearchCV\n",
    "best_regularized_model = grid_rf_reg.best_estimator_\n",
    "print(\"Melhor modelo regularizado selecionado.\")\n",
    "print(\"Melhores parâmetros encontrados:\", grid_rf_reg.best_params_)\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: OBTER PROBABILIDADES\n",
    "# ==============================================================================\n",
    "# Prevemos as probabilidades para os conjuntos de TREINO e TESTE\n",
    "y_probs_train_reg = best_regularized_model.predict_proba(X_train)[:, 1]\n",
    "y_probs_test_reg = best_regularized_model.predict_proba(X_test)[:, 1]\n",
    "print(\"Probabilidades previstas para treino e teste.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: PADRONIZAR OS RÓTULOS PARA {0, 1} (se ainda não tiver feito)\n",
    "# ==============================================================================\n",
    "y_train_mapped = y_train.replace({-1: 0})\n",
    "y_test_mapped = y_test.replace({-1: 0})\n",
    "print(\"Rótulos de treino e teste mapeados para {0, 1}.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 4: ENCONTRAR O LIMIAR ÓTIMO NO CONJUNTO DE TREINO\n",
    "# ==============================================================================\n",
    "precision_reg, recall_reg, thresholds_reg = precision_recall_curve(y_train_mapped, y_probs_train_reg)\n",
    "\n",
    "# Calcula o F1-score para cada limiar\n",
    "f1_scores_reg = 2 * (precision_reg * recall_reg) / (precision_reg + recall_reg)\n",
    "f1_scores_reg = np.nan_to_num(f1_scores_reg)\n",
    "\n",
    "# Encontra o melhor limiar\n",
    "best_f1_idx_reg = np.argmax(f1_scores_reg[:-1])\n",
    "best_threshold_reg = thresholds_reg[best_f1_idx_reg]\n",
    "\n",
    "print(f\"\\nMelhor F1-Score (no treino): {f1_scores_reg[best_f1_idx_reg]:.4f}\")\n",
    "print(f\"Limiar ótimo encontrado: {best_threshold_reg:.4f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 5: VISUALIZAR O TRADE-OFF\n",
    "# ==============================================================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds_reg, precision_reg[:-1], label='Precision')\n",
    "plt.plot(thresholds_reg, recall_reg[:-1], label='Recall')\n",
    "plt.plot(thresholds_reg, f1_scores_reg[:-1], label='F1-Score', linestyle='--')\n",
    "plt.axvline(x=best_threshold_reg, color='black', linestyle=':', label=f'Limiar Ótimo ({best_threshold_reg:.2f})')\n",
    "plt.title('Trade-off do Modelo Regularizado (Dados de Treino)')\n",
    "plt.xlabel('Limiar de Probabilidade')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 6: AVALIAR O DESEMPENHO FINAL NO CONJUNTO DE TESTE\n",
    "# ==============================================================================\n",
    "# Aplica o melhor limiar nas probabilidades do conjunto de teste\n",
    "y_pred_test_optimized_reg = (y_probs_test_reg >= best_threshold_reg).astype(int)\n",
    "\n",
    "# Gera a nova matriz de confusão e métricas\n",
    "cm_optimized_reg = confusion_matrix(y_test_mapped, y_pred_test_optimized_reg)\n",
    "new_f1_score_reg = f1_score(y_test_mapped, y_pred_test_optimized_reg)\n",
    "new_ba_score_reg = balanced_accuracy_score(y_test_mapped, y_pred_test_optimized_reg)\n",
    "\n",
    "print(\"\\n--- RESULTADOS FINAIS NO TESTE (MODELO REGULARIZADO E LIMIAR OTIMIZADO) ---\")\n",
    "print(f\"F1-Score: {new_f1_score_reg:.4f}\")\n",
    "print(f\"Balanced Accuracy: {new_ba_score_reg:.4f}\")\n",
    "\n",
    "# Plotar a Matriz de Confusão Final\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm_optimized_reg, annot=True, fmt='d', cmap='Oranges',\n",
    "            xticklabels=['Previsto Normal (0)', 'Previsto Falha (1)'],\n",
    "            yticklabels=['Real Normal (0)', 'Real Falha (1)'])\n",
    "plt.title(f'Matriz de Confusão Final (Limiar = {best_threshold_reg:.2f})')\n",
    "plt.ylabel('Label Verdadeiro')\n",
    "plt.xlabel('Label Previsto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6cbf7",
   "metadata": {},
   "source": [
    "## 7. Tentando um modelo mais simples (Regressão logistica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# PASSO 1: SETUP E DEFINIÇÃO DOS EXPERIMENTOS\n",
    "# ==============================================================================\n",
    "\n",
    "scenarios_to_tune = ['Sem LDA, Com SMOTE', 'Com LDA, Com SMOTE']\n",
    "MODELO_ALVO = 'LogisticRegression'\n",
    "\n",
    "y_train_mapped = y_train.replace({-1: 0})\n",
    "y_test_mapped = y_test.replace({-1: 0})\n",
    "\n",
    "final_tuned_results = []\n",
    "\n",
    "print(f\"--- Iniciando ajuste de limiar para {MODELO_ALVO} nos cenários com SMOTE ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 2: LOOP PARA AJUSTAR O LIMIAR E AVALIAR CADA CENÁRIO (CORRIGIDO)\n",
    "# ==============================================================================\n",
    "\n",
    "for scenario_name in scenarios_to_tune:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"PROCESSANDO CENÁRIO: {scenario_name}\")\n",
    "    \n",
    "    try:\n",
    "        model_config = next(item for item in all_results if item[\"model\"] == MODELO_ALVO and item[\"scenario\"] == scenario_name)\n",
    "    except (NameError, StopIteration):\n",
    "        print(f\"ERRO: Configuração para '{scenario_name}' não encontrada. Pulando.\")\n",
    "        continue\n",
    "        \n",
    "    best_params = model_config['best_params']\n",
    "    model_params = {key.replace('model__', ''): value for key, value in best_params.items()}\n",
    "    \n",
    "    preprocessor = preprocessor_lda if 'Com LDA' in scenario_name else preprocessor_base\n",
    "    \n",
    "    # --- INÍCIO DA CORREÇÃO ---\n",
    "    # 1. Copiamos os passos do pré-processador para uma nova lista\n",
    "    pipeline_steps = preprocessor.steps.copy()\n",
    "    \n",
    "    # 2. Adicionamos os passos de SMOTE e do modelo a essa lista \"plana\"\n",
    "    pipeline_steps.append(('smote', SMOTE(random_state=42)))\n",
    "    pipeline_steps.append(('model', LogisticRegression(max_iter=2000, random_state=42, **model_params)))\n",
    "    \n",
    "    # 3. Criamos o ImbPipeline a partir da lista de passos desempacotada\n",
    "    final_pipeline = ImbPipeline(pipeline_steps)\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "    \n",
    "    print(\"Treinando o pipeline final...\")\n",
    "    final_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # --- Encontra o limiar ótimo nos dados de TREINO ---\n",
    "    y_probs_train = final_pipeline.predict_proba(X_train)[:, 1]\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train_mapped, y_probs_train)\n",
    "    \n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_scores = np.nan_to_num(f1_scores)\n",
    "    \n",
    "    best_f1_idx = np.argmax(f1_scores[:-1])\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    print(f\"Limiar ótimo encontrado (F1-Score treino): {best_threshold:.4f}\")\n",
    "    \n",
    "    # --- Avalia o desempenho no TESTE com o limiar ótimo ---\n",
    "    y_probs_test = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "    y_pred_optimized = (y_probs_test >= best_threshold).astype(int)\n",
    "    \n",
    "    final_f1 = f1_score(y_test_mapped, y_pred_optimized)\n",
    "    final_ba = balanced_accuracy_score(y_test_mapped, y_pred_optimized)\n",
    "    final_cm = confusion_matrix(y_test_mapped, y_pred_optimized)\n",
    "    \n",
    "    final_tuned_results.append({\n",
    "        'scenario': scenario_name,\n",
    "        'model': MODELO_ALVO,\n",
    "        'final_f1_score': final_f1,\n",
    "        'final_balanced_accuracy': final_ba,\n",
    "        'best_threshold': best_threshold,\n",
    "        'confusion_matrix': final_cm\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(final_cm, annot=True, fmt='d', cmap='viridis')\n",
    "    plt.title(f'Matriz de Confusão Final - {scenario_name}')\n",
    "    plt.ylabel('Label Verdadeiro')\n",
    "    plt.xlabel('Label Previsto')\n",
    "    plt.show()\n",
    "\n",
    "# ==============================================================================\n",
    "# PASSO 3: APRESENTAR A COMPARAÇÃO FINAL\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"## Tabela Comparativa Final (Após Ajuste de Limiar) ##\")\n",
    "\n",
    "summary_df_tuned = pd.DataFrame(final_tuned_results)\n",
    "summary_df_tuned = summary_df_tuned.set_index('scenario')\n",
    "print(summary_df_tuned[['final_f1_score', 'final_balanced_accuracy', 'best_threshold']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773176b",
   "metadata": {},
   "source": [
    "## 8. Conclusões\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6420302",
   "metadata": {},
   "source": [
    "A análise aprofundada dos resultados elege como campeão o modelo de **Regressão Logística** no cenário que combina o pré-processamento com **LDA e SMOTE**. Após um ajuste fino do limiar de decisão para otimizar o F1-Score, este modelo demonstrou ser a abordagem mais eficaz para superar o severo desbalanceamento dos dados e o overfitting, passando de uma performance nula na detecção de falhas para um **F1-Score final de 0.25** no conjunto de teste. Este resultado, embora modesto, representa um avanço crucial, transformando um problema inicialmente intratável em um modelo funcional com capacidade real de identificar defeitos que antes seriam completamente ignorados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
